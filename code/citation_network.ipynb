{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import semanticscholar as sch\n",
    "import urllib\n",
    "import json\n",
    "import requests\n",
    "from fuzzywuzzy import fuzz\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_attributes = pd.read_csv(\"paper_attributes.csv\")\n",
    "our_paper_attributes =  paper_attributes[paper_attributes['Attribute'].isin(['AA.AfId','AA.AfN','AA.AuId','AA.AuN','AA.S','AW','BT','BV','C.CId','C.CN','CC','CitCon','D','ECC','F.FId','F.FN','Id','Pt','RId','Ti','Y'])]\n",
    "our_paper_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_path = os.getcwd()\n",
    "\n",
    "file_path_iclr = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_ICLR.json', cur_path)\n",
    "file_path_acl = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_ACL.json', cur_path)\n",
    "file_path_cvpr = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_CVPR.json', cur_path)\n",
    "file_path_emnlp = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_EMNLP.json', cur_path)\n",
    "file_path_iccv = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_ICCV.json', cur_path)\n",
    "file_path_iclr = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_ICLR.json', cur_path)\n",
    "file_path_icml = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_ICML.json', cur_path)\n",
    "file_path_naacl = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_NAACL.json', cur_path)\n",
    "file_path_neurips = os.path.relpath('..\\\\data\\\\paper_data_mag\\\\MAG_NEURIPS.json', cur_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_data_df(file_path):\n",
    "    with open(file_path) as f_in:\n",
    "        paper_data_dict = json.load(f_in)\n",
    "    paper_data_records = paper_data_dict['entities']\n",
    "    paper_data_df = pd.DataFrame.from_records(paper_data_records)\n",
    "    return paper_data_df\n",
    "\n",
    "def fuzzy_matching(x,y):\n",
    "    return True if fuzz.ratio(x,y) > 90 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1735it [00:00, 8015.37it/s]\n",
      "2594it [00:00, 4784.73it/s]\n",
      "5236it [00:00, 5980.71it/s]\n",
      "1817it [00:00, 5829.72it/s]\n",
      "1701it [00:00, 6090.51it/s]\n",
      "3485it [00:00, 11973.94it/s]\n",
      "1390it [00:00, 6935.02it/s]\n",
      "2516it [00:00, 11451.22it/s]\n"
     ]
    }
   ],
   "source": [
    "iclr_paper_data = create_paper_data_df(file_path_iclr)\n",
    "references_list_iclr = [(rid,row['Id']) for idx,row in tqdm(iclr_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "acl_paper_data = create_paper_data_df(file_path_acl)\n",
    "references_list_acl = [(rid,row['Id']) for idx,row in tqdm(acl_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "cvpr_paper_data = create_paper_data_df(file_path_cvpr)\n",
    "references_list_cvpr = [(rid,row['Id']) for idx,row in tqdm(cvpr_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "emnlp_paper_data = create_paper_data_df(file_path_emnlp)\n",
    "references_list_emnlp = [(rid,row['Id']) for idx,row in tqdm(emnlp_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "iccv_paper_data = create_paper_data_df(file_path_iccv)\n",
    "references_list_iccv = [(rid,row['Id']) for idx,row in tqdm(iccv_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "icml_paper_data = create_paper_data_df(file_path_icml)\n",
    "references_list_icml = [(rid,row['Id']) for idx,row in tqdm(icml_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "naacl_paper_data = create_paper_data_df(file_path_naacl)\n",
    "references_list_naacl = [(rid,row['Id']) for idx,row in tqdm(naacl_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n",
    "\n",
    "neurips_paper_data = create_paper_data_df(file_path_neurips)\n",
    "references_list_neurips = [(rid,row['Id']) for idx,row in tqdm(neurips_paper_data.iterrows()) if type(row['RId'])!=float for rid in row['RId']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paper_data_df = pd.concat([iclr_paper_data, acl_paper_data, cvpr_paper_data, emnlp_paper_data, iccv_paper_data, icml_paper_data, naacl_paper_data, neurips_paper_data])\n",
    "all_paper_data_df.to_pickle(\"..\\\\data\\\\all_paper_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paper_data_df = pd.read_pickle(\"..\\\\data\\\\all_paper_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df_iclr = pd.DataFrame(references_list_iclr, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_acl = pd.DataFrame(references_list_acl, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_cvpr = pd.DataFrame(references_list_cvpr, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_emnlp = pd.DataFrame(references_list_emnlp, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_iccv = pd.DataFrame(references_list_iccv, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_icml = pd.DataFrame(references_list_icml, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_naacl = pd.DataFrame(references_list_naacl, columns=['this_paper_infected','got_infected_by'])\n",
    "reference_df_neurips = pd.DataFrame(references_list_neurips, columns=['this_paper_infected','got_infected_by'])\n",
    "\n",
    "reference_df = pd.concat([reference_df_iclr, reference_df_acl, reference_df_cvpr, reference_df_emnlp, reference_df_iccv, reference_df_icml, reference_df_naacl, reference_df_neurips])\n",
    "reference_df.to_pickle(\"..\\\\data\\\\networks\\\\citation_network.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>this_paper_infected</th>\n",
       "      <th>got_infected_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2963403868</td>\n",
       "      <td>2785994986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963207607</td>\n",
       "      <td>2785994986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2134557905</td>\n",
       "      <td>2785994986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2154579312</td>\n",
       "      <td>2785994986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2966661</td>\n",
       "      <td>2785994986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2482888308</td>\n",
       "      <td>2897127218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2057624533</td>\n",
       "      <td>2897127218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2103458172</td>\n",
       "      <td>2897127218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2136885855</td>\n",
       "      <td>2897127218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2804140211</td>\n",
       "      <td>2897127218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      this_paper_infected  got_infected_by\n",
       "0              2963403868       2785994986\n",
       "1              2963207607       2785994986\n",
       "2              2134557905       2785994986\n",
       "3              2154579312       2785994986\n",
       "4                 2966661       2785994986\n",
       "...                   ...              ...\n",
       "2191           2482888308       2897127218\n",
       "2192           2057624533       2897127218\n",
       "2193           2103458172       2897127218\n",
       "2194           2136885855       2897127218\n",
       "2195           2804140211       2897127218\n",
       "\n",
       "[409472 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409472it [02:49, 2417.06it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_idx_infection = []\n",
    "for idx,row in tqdm(reference_df.iterrows()):\n",
    "    \n",
    "    source = row['this_paper_infected']\n",
    "    destination = row['got_infected_by']\n",
    "    if source in all_paper_data_df['Id'].values and destination in all_paper_data_df['Id'].values:\n",
    "        source_abstract = all_paper_data_df[all_paper_data_df['Id'] == source]['AW'].values[0]\n",
    "        dest_abstract = all_paper_data_df[all_paper_data_df['Id'] == destination]['AW'].values[0]\n",
    "        source_fos = all_paper_data_df[all_paper_data_df['Id'] == source]['F'].values[0]\n",
    "        dest_fos = all_paper_data_df[all_paper_data_df['Id'] == destination]['F'].values[0]\n",
    "        if type(source_abstract) != float and type(dest_abstract) != float and type(source_fos) != float and type(dest_fos) != float:\n",
    "            #abstract overlap\n",
    "            source_abstract = set(source_abstract)\n",
    "            dest_abstract = set(dest_abstract)\n",
    "            abstract_overlap_score = len(set.intersection(source_abstract,dest_abstract))/len(source_abstract)\n",
    "            #FOS overlap\n",
    "            source_fos = set([pair['FN'] for pair in source_fos])\n",
    "            dest_fos = set([pair['FN'] for pair in dest_fos])\n",
    "            fos_overlap_score = len(set.intersection(source_fos,dest_fos))/len(source_fos)\n",
    "            if abstract_overlap_score > 0.20 and fos_overlap_score > 0.20:\n",
    "                valid_idx_infection.append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>this_paper_infected</th>\n",
       "      <th>got_infected_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2963283805</td>\n",
       "      <td>2996287690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2963466651</td>\n",
       "      <td>2996287690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2892153332</td>\n",
       "      <td>2996287690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2963595537</td>\n",
       "      <td>2996287690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2963026768</td>\n",
       "      <td>2996035354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2963403868</td>\n",
       "      <td>2994689640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2970771982</td>\n",
       "      <td>2996403597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2242818861</td>\n",
       "      <td>2996201207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>2896409484</td>\n",
       "      <td>2996309822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>2560647685</td>\n",
       "      <td>2996653965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9345 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     this_paper_infected  got_infected_by\n",
       "96            2963283805       2996287690\n",
       "100           2963466651       2996287690\n",
       "106           2892153332       2996287690\n",
       "108           2963595537       2996287690\n",
       "163           2963026768       2996035354\n",
       "..                   ...              ...\n",
       "129           2963403868       2994689640\n",
       "255           2970771982       2996403597\n",
       "417           2242818861       2996201207\n",
       "893           2896409484       2996309822\n",
       "964           2560647685       2996653965\n",
       "\n",
       "[9345 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infected_df = reference_df.iloc[valid_idx_infection, :]\n",
    "infected_df.to_pickle(\"..\\\\data\\\\networks\\\\citation_infection_network.pkl\")\n",
    "infected_df = pd.read_pickle(\"..\\\\data\\\\networks\\\\citation_infection_network.pkl\")\n",
    "infected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_citation = nx.from_pandas_edgelist(infected_df, source='this_paper_infected', target='got_infected_by',create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20474it [04:46, 71.41it/s]\n"
     ]
    }
   ],
   "source": [
    "cur_path = os.getcwd()\n",
    "review_df = pd.read_pickle(\"..\\\\data\\\\paper_quality\\\\review_data.pkl\")\n",
    "\n",
    "review_df['mag_id'] = [None]*len(review_df)\n",
    "for idx,row in tqdm(all_paper_data_df.iterrows()):\n",
    "    match_series = review_df['title'].apply(lambda x : fuzzy_matching(x,row['Ti']))\n",
    "    match = review_df.loc[match_series == True]\n",
    "    if len(match)>0:\n",
    "        review_df.loc[match.index[0],'mag_id'] = row['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forum</th>\n",
       "      <th>review_ratings</th>\n",
       "      <th>decision</th>\n",
       "      <th>submission_content</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>mag_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hk6kPgZA-</td>\n",
       "      <td>[9: Top 15% of accepted papers, strong accept,...</td>\n",
       "      <td>Accept (Oral)</td>\n",
       "      <td>{'title': 'Certifying Some Distributional Robu...</td>\n",
       "      <td>strong</td>\n",
       "      <td>Certifying Some Distributional Robustness with...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ByED-X-0W</td>\n",
       "      <td>[4: Ok but not good enough - rejection, 6: Mar...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>{'title': 'Parametric Information Bottleneck t...</td>\n",
       "      <td>avg</td>\n",
       "      <td>Parametric Information Bottleneck to Optimize ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HktJec1RZ</td>\n",
       "      <td>[6: Marginally above acceptance threshold, 6: ...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>{'title': 'Towards Neural Phrase-based Machine...</td>\n",
       "      <td>good</td>\n",
       "      <td>Towards Neural Phrase-based Machine Translation</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1pWFzbAW</td>\n",
       "      <td>[6: Marginally above acceptance threshold, 6: ...</td>\n",
       "      <td>Invite to Workshop Track</td>\n",
       "      <td>{'title': 'Weightless: Lossy Weight Encoding F...</td>\n",
       "      <td>avg</td>\n",
       "      <td>Weightless: Lossy Weight Encoding For Deep Neu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H1UOm4gA-</td>\n",
       "      <td>[7: Good paper, accept, 6: Marginally above ac...</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>{'title': 'Interactive Grounded Language Acqui...</td>\n",
       "      <td>good</td>\n",
       "      <td>Interactive Grounded Language Acquisition and ...</td>\n",
       "      <td>2962891854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>HJ5AUm-CZ</td>\n",
       "      <td>[7: Good paper, accept, 5: Marginally below ac...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>{'title': 'The Variational Homoencoder: Learni...</td>\n",
       "      <td>good</td>\n",
       "      <td>The Variational Homoencoder: Learning to Infer...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>rJ5C67-C-</td>\n",
       "      <td>[5: Marginally below acceptance threshold, 5: ...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>{'title': 'Hyperedge2vec: Distributed Represen...</td>\n",
       "      <td>avg</td>\n",
       "      <td>Hyperedge2vec: Distributed Representations for...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>HkPCrEZ0Z</td>\n",
       "      <td>[5: Marginally below acceptance threshold, 5: ...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>{'title': 'Combining Model-based and Model-fre...</td>\n",
       "      <td>avg</td>\n",
       "      <td>Combining Model-based and Model-free RL via Mu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Syt0r4bRZ</td>\n",
       "      <td>[2: Strong rejection, 5: Marginally below acce...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>{'title': 'Tree2Tree Learning with Memory Unit...</td>\n",
       "      <td>avg</td>\n",
       "      <td>Tree2Tree Learning with Memory Unit</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>S1sRrN-CW</td>\n",
       "      <td>[3: Clear rejection, 5: Marginally below accep...</td>\n",
       "      <td>Reject</td>\n",
       "      <td>{'title': 'Revisiting Knowledge Base Embedding...</td>\n",
       "      <td>avg</td>\n",
       "      <td>Revisiting Knowledge Base Embedding as Tensor ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         forum                                     review_ratings  \\\n",
       "0    Hk6kPgZA-  [9: Top 15% of accepted papers, strong accept,...   \n",
       "1    ByED-X-0W  [4: Ok but not good enough - rejection, 6: Mar...   \n",
       "2    HktJec1RZ  [6: Marginally above acceptance threshold, 6: ...   \n",
       "3    S1pWFzbAW  [6: Marginally above acceptance threshold, 6: ...   \n",
       "4    H1UOm4gA-  [7: Good paper, accept, 6: Marginally above ac...   \n",
       "..         ...                                                ...   \n",
       "905  HJ5AUm-CZ  [7: Good paper, accept, 5: Marginally below ac...   \n",
       "906  rJ5C67-C-  [5: Marginally below acceptance threshold, 5: ...   \n",
       "907  HkPCrEZ0Z  [5: Marginally below acceptance threshold, 5: ...   \n",
       "908  Syt0r4bRZ  [2: Strong rejection, 5: Marginally below acce...   \n",
       "909  S1sRrN-CW  [3: Clear rejection, 5: Marginally below accep...   \n",
       "\n",
       "                     decision  \\\n",
       "0               Accept (Oral)   \n",
       "1                      Reject   \n",
       "2             Accept (Poster)   \n",
       "3    Invite to Workshop Track   \n",
       "4             Accept (Poster)   \n",
       "..                        ...   \n",
       "905                    Reject   \n",
       "906                    Reject   \n",
       "907                    Reject   \n",
       "908                    Reject   \n",
       "909                    Reject   \n",
       "\n",
       "                                    submission_content  rating  \\\n",
       "0    {'title': 'Certifying Some Distributional Robu...  strong   \n",
       "1    {'title': 'Parametric Information Bottleneck t...     avg   \n",
       "2    {'title': 'Towards Neural Phrase-based Machine...    good   \n",
       "3    {'title': 'Weightless: Lossy Weight Encoding F...     avg   \n",
       "4    {'title': 'Interactive Grounded Language Acqui...    good   \n",
       "..                                                 ...     ...   \n",
       "905  {'title': 'The Variational Homoencoder: Learni...    good   \n",
       "906  {'title': 'Hyperedge2vec: Distributed Represen...     avg   \n",
       "907  {'title': 'Combining Model-based and Model-fre...     avg   \n",
       "908  {'title': 'Tree2Tree Learning with Memory Unit...     avg   \n",
       "909  {'title': 'Revisiting Knowledge Base Embedding...     avg   \n",
       "\n",
       "                                                 title      mag_id  \n",
       "0    Certifying Some Distributional Robustness with...        None  \n",
       "1    Parametric Information Bottleneck to Optimize ...        None  \n",
       "2      Towards Neural Phrase-based Machine Translation        None  \n",
       "3    Weightless: Lossy Weight Encoding For Deep Neu...        None  \n",
       "4    Interactive Grounded Language Acquisition and ...  2962891854  \n",
       "..                                                 ...         ...  \n",
       "905  The Variational Homoencoder: Learning to Infer...        None  \n",
       "906  Hyperedge2vec: Distributed Representations for...        None  \n",
       "907  Combining Model-based and Model-free RL via Mu...        None  \n",
       "908                Tree2Tree Learning with Memory Unit        None  \n",
       "909  Revisiting Knowledge Base Embedding as Tensor ...        None  \n",
       "\n",
       "[910 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.to_pickle(\"..\\\\data\\\\paper_quality\\\\review_data_with_mag_id.pkl\")\n",
    "review_df_with_mag_id = pd.read_pickle(\"..\\\\data\\\\paper_quality\\\\review_data_with_mag_id.pkl\")\n",
    "review_df_with_mag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2962891854</td>\n",
       "      <td>good</td>\n",
       "      <td>0.248911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963420658</td>\n",
       "      <td>good</td>\n",
       "      <td>0.496263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2964098744</td>\n",
       "      <td>good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2963477238</td>\n",
       "      <td>good</td>\n",
       "      <td>0.248911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2963329163</td>\n",
       "      <td>good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2787849668</td>\n",
       "      <td>avg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2963471276</td>\n",
       "      <td>good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2786686245</td>\n",
       "      <td>avg</td>\n",
       "      <td>0.373273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2785940258</td>\n",
       "      <td>weak</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2786230348</td>\n",
       "      <td>good</td>\n",
       "      <td>0.521330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mag_id rating  prestige\n",
       "0   2962891854   good  0.248911\n",
       "1   2963420658   good  0.496263\n",
       "2   2964098744   good       NaN\n",
       "3   2963477238   good  0.248911\n",
       "4   2963329163   good       NaN\n",
       "..         ...    ...       ...\n",
       "72  2787849668    avg       NaN\n",
       "73  2963471276   good       NaN\n",
       "74  2786686245    avg  0.373273\n",
       "75  2785940258   weak       NaN\n",
       "76  2786230348   good  0.521330\n",
       "\n",
       "[77 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_zero_ids = [row['mag_id'] for idx,row in review_df_with_mag_id.iterrows() if row['mag_id'] is not None]\n",
    "patient_zero_ratings = [review_df_with_mag_id[review_df_with_mag_id['mag_id'] == mag_id]['rating'].values[0] for mag_id in patient_zero_ids]\n",
    "\n",
    "affiliation_df = pd.read_pickle(\"..\\\\data\\\\prestige\\\\prestige_data.pkl\")\n",
    "patient_zero_prestiges = []\n",
    "for patient_zero in patient_zero_ids:\n",
    "    author_affiliations = [authdict['AfId'] for authdict in all_paper_data_df[all_paper_data_df['Id'] == patient_zero]['AA'].values[0]]\n",
    "    prestiges = [affiliation_df[affiliation_df['id'] == affiliation]['prestige'].values[0] for affiliation in author_affiliations if affiliation is not None]\n",
    "    prestiges = [item for item in prestiges if str(item) != 'nan']\n",
    "    if len(prestiges)>0:\n",
    "        patient_zero_prestiges.append(statistics.mean(prestiges))\n",
    "    else:\n",
    "        patient_zero_prestiges.append(None)\n",
    "\n",
    "patient_zero_df = pd.DataFrame()\n",
    "patient_zero_df['mag_id'] = patient_zero_ids\n",
    "patient_zero_df['rating'] = patient_zero_ratings\n",
    "patient_zero_df['prestige'] = patient_zero_prestiges\n",
    "patient_zero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = list(reference_df_neurips['this_paper_infected'][:9])\n",
    "# r.append(2613718673)\n",
    "# k = G_citation.subgraph(r)\n",
    "# nx.draw(k,with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logprob</th>\n",
       "      <th>prob</th>\n",
       "      <th>Id</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Pt</th>\n",
       "      <th>Y</th>\n",
       "      <th>D</th>\n",
       "      <th>CC</th>\n",
       "      <th>ECC</th>\n",
       "      <th>DN</th>\n",
       "      <th>BV</th>\n",
       "      <th>BT</th>\n",
       "      <th>AA</th>\n",
       "      <th>F</th>\n",
       "      <th>C</th>\n",
       "      <th>DOI</th>\n",
       "      <th>RId</th>\n",
       "      <th>AW</th>\n",
       "      <th>CitCon</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-15.329</td>\n",
       "      <td>2.201405e-07</td>\n",
       "      <td>2964253222</td>\n",
       "      <td>towards deep learning models resistant to adve...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>1617</td>\n",
       "      <td>2100</td>\n",
       "      <td>Towards Deep Learning Models Resistant to Adve...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'aleksander madry', 'AuId': 213771398...</td>\n",
       "      <td>[{'FN': 'adversarial machine learning', 'FId':...</td>\n",
       "      <td>{'CN': 'iclr', 'CId': 2584161585}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.819</td>\n",
       "      <td>1.348639e-07</td>\n",
       "      <td>2962760235</td>\n",
       "      <td>progressive growing of gans for improved quali...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>1085</td>\n",
       "      <td>1232</td>\n",
       "      <td>Progressive Growing of GANs for Improved Quali...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'tero karras', 'AuId': 2153729192, 'A...</td>\n",
       "      <td>[{'FN': 'unsupervised learning', 'FId': 803899...</td>\n",
       "      <td>{'CN': 'iclr', 'CId': 2584161585}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.841</td>\n",
       "      <td>1.319293e-07</td>\n",
       "      <td>2963858333</td>\n",
       "      <td>graph attention networks</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>1142</td>\n",
       "      <td>1341</td>\n",
       "      <td>Graph Attention Networks.</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'petar velickovic', 'AuId': 240300360...</td>\n",
       "      <td>[{'FN': 'theoretical computer science', 'FId':...</td>\n",
       "      <td>{'CN': 'iclr', 'CId': 2584161585}</td>\n",
       "      <td>10.17863/CAM.48429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.184</td>\n",
       "      <td>9.362204e-08</td>\n",
       "      <td>2963836885</td>\n",
       "      <td>spectral normalization for generative adversar...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>960</td>\n",
       "      <td>1071</td>\n",
       "      <td>Spectral Normalization for Generative Adversar...</td>\n",
       "      <td>International Conference on Learning Represent...</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'takeru miyato', 'AuId': 2252860004, ...</td>\n",
       "      <td>[{'FN': 'normalization', 'FId': 123832482}, {'...</td>\n",
       "      <td>{'CN': 'iclr', 'CId': 2584161585}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.297</td>\n",
       "      <td>8.361859e-08</td>\n",
       "      <td>2963310665</td>\n",
       "      <td>glue a multi task benchmark and analysis platf...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>767</td>\n",
       "      <td>767</td>\n",
       "      <td>GLUE: A Multi-Task Benchmark and Analysis Plat...</td>\n",
       "      <td>7th International Conference on Learning Repre...</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'alex wang', 'AuId': 2798400918, 'AfN...</td>\n",
       "      <td>[{'FN': 'natural language understanding', 'FId...</td>\n",
       "      <td>{'CN': 'iclr', 'CId': 2584161585}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>-22.432</td>\n",
       "      <td>1.810949e-10</td>\n",
       "      <td>2890533838</td>\n",
       "      <td>revisiting e γ τ similarity learning for domai...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Revisiting (ε, γ, τ)-similarity learning for d...</td>\n",
       "      <td>NeurIPS 2018</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'sofien dhouib', 'AuId': 3035546768, ...</td>\n",
       "      <td>[{'FN': 'similarity learning', 'FId': 27795972...</td>\n",
       "      <td>{'CN': 'neurips', 'CId': 1127325140}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[similarity, learning, active, research, area,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>-22.536</td>\n",
       "      <td>1.632073e-10</td>\n",
       "      <td>2971118620</td>\n",
       "      <td>partitioning structure learning for segmented ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Partitioning Structure Learning for Segmented ...</td>\n",
       "      <td>Advances in Neural Information Processing Systems</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'xiangyu zheng', 'AuId': 2970171545, ...</td>\n",
       "      <td>[{'FN': 'recursive partitioning', 'FId': 13734...</td>\n",
       "      <td>{'CN': 'neurips', 'CId': 1127325140}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[paper, proposes, partitioning, structure, lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>-22.586</td>\n",
       "      <td>1.552476e-10</td>\n",
       "      <td>2970505003</td>\n",
       "      <td>optimal pricing in repeated posted price aucti...</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Optimal Pricing in Repeated Posted-Price Aucti...</td>\n",
       "      <td>Advances in Neural Information Processing Systems</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'arsenii vanunts', 'AuId': 2801896095...</td>\n",
       "      <td>[{'FN': 'common value auction', 'FId': 1632397...</td>\n",
       "      <td>{'CN': 'neurips', 'CId': 1127325140}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[revenue, optimization, pricing, algorithms, r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>-22.637</td>\n",
       "      <td>1.475285e-10</td>\n",
       "      <td>2892301404</td>\n",
       "      <td>non ergodic alternating proximal augmented lag...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Ergodic Alternating Proximal Augmented Lag...</td>\n",
       "      <td>Advances in Neural Information Processing Systems</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'quoc tran dinh', 'AuId': 3093086551,...</td>\n",
       "      <td>[{'FN': 'augmented lagrangian method', 'FId': ...</td>\n",
       "      <td>{'CN': 'neurips', 'CId': 1127325140}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[develop, two, ergodic, alternating, proximal,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>-22.640</td>\n",
       "      <td>1.470865e-10</td>\n",
       "      <td>2910165496</td>\n",
       "      <td>differentiating between models of perceptual d...</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Differentiating Between Models of Perceptual D...</td>\n",
       "      <td>8th Joint CIN-NIPS Symposium</td>\n",
       "      <td>p</td>\n",
       "      <td>[{'AuN': 'k kawaguchi', 'AuId': 2909062921, 'A...</td>\n",
       "      <td>[{'FN': 'cognitive psychology', 'FId': 1807472...</td>\n",
       "      <td>{'CN': 'neurips', 'CId': 1127325140}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20474 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      logprob          prob          Id  \\\n",
       "0     -15.329  2.201405e-07  2964253222   \n",
       "1     -15.819  1.348639e-07  2962760235   \n",
       "2     -15.841  1.319293e-07  2963858333   \n",
       "3     -16.184  9.362204e-08  2963836885   \n",
       "4     -16.297  8.361859e-08  2963310665   \n",
       "...       ...           ...         ...   \n",
       "2511  -22.432  1.810949e-10  2890533838   \n",
       "2512  -22.536  1.632073e-10  2971118620   \n",
       "2513  -22.586  1.552476e-10  2970505003   \n",
       "2514  -22.637  1.475285e-10  2892301404   \n",
       "2515  -22.640  1.470865e-10  2910165496   \n",
       "\n",
       "                                                     Ti Pt     Y           D  \\\n",
       "0     towards deep learning models resistant to adve...  3  2018  2018-02-15   \n",
       "1     progressive growing of gans for improved quali...  3  2018  2018-02-15   \n",
       "2                              graph attention networks  3  2018  2018-02-15   \n",
       "3     spectral normalization for generative adversar...  3  2018  2018-02-15   \n",
       "4     glue a multi task benchmark and analysis platf...  3  2018  2018-04-20   \n",
       "...                                                 ... ..   ...         ...   \n",
       "2511  revisiting e γ τ similarity learning for domai...  3  2018  2018-12-03   \n",
       "2512  partitioning structure learning for segmented ...  3  2019  2019-01-01   \n",
       "2513  optimal pricing in repeated posted price aucti...  3  2019  2019-01-01   \n",
       "2514  non ergodic alternating proximal augmented lag...  3  2018  2018-01-01   \n",
       "2515  differentiating between models of perceptual d...  3  2018  2018-10-01   \n",
       "\n",
       "        CC   ECC                                                 DN  \\\n",
       "0     1617  2100  Towards Deep Learning Models Resistant to Adve...   \n",
       "1     1085  1232  Progressive Growing of GANs for Improved Quali...   \n",
       "2     1142  1341                          Graph Attention Networks.   \n",
       "3      960  1071  Spectral Normalization for Generative Adversar...   \n",
       "4      767   767  GLUE: A Multi-Task Benchmark and Analysis Plat...   \n",
       "...    ...   ...                                                ...   \n",
       "2511     0     0  Revisiting (ε, γ, τ)-similarity learning for d...   \n",
       "2512     0     0  Partitioning Structure Learning for Segmented ...   \n",
       "2513     0     0  Optimal Pricing in Repeated Posted-Price Aucti...   \n",
       "2514     0     0  Non-Ergodic Alternating Proximal Augmented Lag...   \n",
       "2515     0     0  Differentiating Between Models of Perceptual D...   \n",
       "\n",
       "                                                     BV BT  \\\n",
       "0     International Conference on Learning Represent...  p   \n",
       "1     International Conference on Learning Represent...  p   \n",
       "2     International Conference on Learning Represent...  p   \n",
       "3     International Conference on Learning Represent...  p   \n",
       "4     7th International Conference on Learning Repre...  p   \n",
       "...                                                 ... ..   \n",
       "2511                                       NeurIPS 2018  p   \n",
       "2512  Advances in Neural Information Processing Systems  p   \n",
       "2513  Advances in Neural Information Processing Systems  p   \n",
       "2514  Advances in Neural Information Processing Systems  p   \n",
       "2515                       8th Joint CIN-NIPS Symposium  p   \n",
       "\n",
       "                                                     AA  \\\n",
       "0     [{'AuN': 'aleksander madry', 'AuId': 213771398...   \n",
       "1     [{'AuN': 'tero karras', 'AuId': 2153729192, 'A...   \n",
       "2     [{'AuN': 'petar velickovic', 'AuId': 240300360...   \n",
       "3     [{'AuN': 'takeru miyato', 'AuId': 2252860004, ...   \n",
       "4     [{'AuN': 'alex wang', 'AuId': 2798400918, 'AfN...   \n",
       "...                                                 ...   \n",
       "2511  [{'AuN': 'sofien dhouib', 'AuId': 3035546768, ...   \n",
       "2512  [{'AuN': 'xiangyu zheng', 'AuId': 2970171545, ...   \n",
       "2513  [{'AuN': 'arsenii vanunts', 'AuId': 2801896095...   \n",
       "2514  [{'AuN': 'quoc tran dinh', 'AuId': 3093086551,...   \n",
       "2515  [{'AuN': 'k kawaguchi', 'AuId': 2909062921, 'A...   \n",
       "\n",
       "                                                      F  \\\n",
       "0     [{'FN': 'adversarial machine learning', 'FId':...   \n",
       "1     [{'FN': 'unsupervised learning', 'FId': 803899...   \n",
       "2     [{'FN': 'theoretical computer science', 'FId':...   \n",
       "3     [{'FN': 'normalization', 'FId': 123832482}, {'...   \n",
       "4     [{'FN': 'natural language understanding', 'FId...   \n",
       "...                                                 ...   \n",
       "2511  [{'FN': 'similarity learning', 'FId': 27795972...   \n",
       "2512  [{'FN': 'recursive partitioning', 'FId': 13734...   \n",
       "2513  [{'FN': 'common value auction', 'FId': 1632397...   \n",
       "2514  [{'FN': 'augmented lagrangian method', 'FId': ...   \n",
       "2515  [{'FN': 'cognitive psychology', 'FId': 1807472...   \n",
       "\n",
       "                                         C                 DOI  RId  \\\n",
       "0        {'CN': 'iclr', 'CId': 2584161585}                 NaN  NaN   \n",
       "1        {'CN': 'iclr', 'CId': 2584161585}                 NaN  NaN   \n",
       "2        {'CN': 'iclr', 'CId': 2584161585}  10.17863/CAM.48429  NaN   \n",
       "3        {'CN': 'iclr', 'CId': 2584161585}                 NaN  NaN   \n",
       "4        {'CN': 'iclr', 'CId': 2584161585}                 NaN  NaN   \n",
       "...                                    ...                 ...  ...   \n",
       "2511  {'CN': 'neurips', 'CId': 1127325140}                 NaN  NaN   \n",
       "2512  {'CN': 'neurips', 'CId': 1127325140}                 NaN  NaN   \n",
       "2513  {'CN': 'neurips', 'CId': 1127325140}                 NaN  NaN   \n",
       "2514  {'CN': 'neurips', 'CId': 1127325140}                 NaN  NaN   \n",
       "2515  {'CN': 'neurips', 'CId': 1127325140}                 NaN  NaN   \n",
       "\n",
       "                                                     AW CitCon    FP  \n",
       "0                                                   NaN    NaN   NaN  \n",
       "1                                                   NaN    NaN   NaN  \n",
       "2                                                   NaN    NaN   NaN  \n",
       "3                                                   NaN    NaN   NaN  \n",
       "4                                                   NaN    NaN   NaN  \n",
       "...                                                 ...    ...   ...  \n",
       "2511  [similarity, learning, active, research, area,...    NaN   NaN  \n",
       "2512  [paper, proposes, partitioning, structure, lea...    NaN  2222  \n",
       "2513  [revenue, optimization, pricing, algorithms, r...    NaN   941  \n",
       "2514  [develop, two, ergodic, alternating, proximal,...    NaN  4811  \n",
       "2515                                                NaN    NaN   NaN  \n",
       "\n",
       "[20474 rows x 20 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paper_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
